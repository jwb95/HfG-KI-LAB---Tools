{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stylegan2_wikiart_unconditional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Referenz:\n",
        "\n",
        "https://github.com/pbaylies/stylegan2-ada\n",
        "\n",
        "https://github.com/pbaylies/stylegan2-ada/blob/main/WikiArt%20Example%20Generation.ipynb"
      ],
      "metadata": {
        "id": "I4GpTdU4PQNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "sHouh2YYPTaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install missing packages\n",
        "!pip install opensimplex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p1Dtz2pPXEM",
        "outputId": "2207eae4-7a7c-4e15-9275-99b1390b91e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opensimplex\n",
            "  Downloading opensimplex-0.4.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from opensimplex) (1.21.5)\n",
            "Installing collected packages: opensimplex\n",
            "Successfully installed opensimplex-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone pbaylies' stylegan2 fork\n",
        "%cd /content/\n",
        "!git clone https://github.com/pbaylies/stylegan2-ada\n",
        "%cd /content/stylegan2-ada\n",
        "!mkdir out\n",
        "outdir=\"out\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pApyw8WiPdyt",
        "outputId": "ad1e3a99-3f46-4b37-8854-4bd09deed383"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Total 361 (delta 0), reused 0 (delta 0), pack-reused 361\u001b[K\n",
            "Receiving objects: 100% (361/361), 61.57 MiB | 25.07 MiB/s, done.\n",
            "Resolving deltas: 100% (196/196), done.\n",
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select tensorflow 1.x instead of 2.x\n",
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSX1YqaOTAAO",
        "outputId": "f12f57d9-c680-4f66-ef44-80df1f4ee293"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8fiUAYSKC-V",
        "outputId": "b6ab9c1c-5cc6-4383-ebcb-b2826b49306f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-18 14:48:01--  https://archive.org/download/wikiart-stylegan2-conditional-model/WikiArt_Uncond2.pkl\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia802803.us.archive.org/30/items/wikiart-stylegan2-conditional-model/WikiArt_Uncond2.pkl [following]\n",
            "--2022-02-18 14:48:01--  https://ia802803.us.archive.org/30/items/wikiart-stylegan2-conditional-model/WikiArt_Uncond2.pkl\n",
            "Resolving ia802803.us.archive.org (ia802803.us.archive.org)... 207.241.232.113\n",
            "Connecting to ia802803.us.archive.org (ia802803.us.archive.org)|207.241.232.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381615715 (364M) [application/octet-stream]\n",
            "Saving to: ‘WikiArt_Uncond2.pkl’\n",
            "\n",
            "WikiArt_Uncond2.pkl 100%[===================>] 363.94M   812KB/s    in 9m 39s  \n",
            "\n",
            "2022-02-18 14:57:41 (643 KB/s) - ‘WikiArt_Uncond2.pkl’ saved [381615715/381615715]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download wikiart unconditional pretrained model\n",
        "!wget https://archive.org/download/wikiart-stylegan2-conditional-model/WikiArt_Uncond2.pkl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libs\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import pickle\n",
        "import re\n",
        "from projector import Projector\n",
        "import tqdm\n",
        "import imageio\n",
        "\n",
        "import scipy\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
        "import cv2\n",
        "import moviepy.editor\n",
        "from opensimplex import OpenSimplex\n",
        "\n",
        "import warnings # mostly numpy warnings for me\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcVT2shWRu1d",
        "outputId": "47258cdb-422e-48cd-9e3b-e6d466954125"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2547712/45929032 bytes (5.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6111232/45929032 bytes (13.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9584640/45929032 bytes (20.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12976128/45929032 bytes (28.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16449536/45929032 bytes (35.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19939328/45929032 bytes (43.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23273472/45929032 bytes (50.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26738688/45929032 bytes (58.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30277632/45929032 bytes (65.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33570816/45929032 bytes (73.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37068800/45929032 bytes (80.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40443904/45929032 bytes (88.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43941888/45929032 bytes (95.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions\n",
        "\n",
        "def create_image_grid(images, grid_size=None):\n",
        "    '''\n",
        "    Args:\n",
        "        images (np.array): images to place on the grid\n",
        "        grid_size (tuple(int, int)): size of grid (grid_w, grid_h)\n",
        "    Returns:\n",
        "        grid (np.array): image grid of size grid_size\n",
        "    '''\n",
        "    # Some sanity check:\n",
        "    assert images.ndim == 3 or images.ndim == 4\n",
        "    num, img_h, img_w = images.shape[0], images.shape[1], images.shape[2]\n",
        "    if grid_size is not None:\n",
        "        grid_w, grid_h = tuple(grid_size)\n",
        "    else:\n",
        "        grid_w = max(int(np.ceil(np.sqrt(num))), 1)\n",
        "        grid_h = max((num - 1) // grid_w + 1, 1)\n",
        "    # Get the grid\n",
        "    grid = np.zeros(\n",
        "        [grid_h * img_h, grid_w * img_w] + list(images.shape[-1:]), dtype=images.dtype\n",
        "    )\n",
        "    for idx in range(num):\n",
        "        x = (idx % grid_w) * img_w\n",
        "        y = (idx // grid_w) * img_h\n",
        "        grid[y : y + img_h, x : x + img_w, ...] = images[idx]\n",
        "    return grid\n",
        "\n",
        "def render_from_zs(Gs, zs, w_space=False, grid=False, class_idx=None, prefix=''):\n",
        "    images = []\n",
        "    Gs_kwargs = {\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
        "        'randomize_noise': False\n",
        "    }\n",
        "    label = np.zeros([1] + Gs.input_shapes[1][1:])\n",
        "    if class_idx is not None:\n",
        "        label[:, class_idx] = 1\n",
        "    for i_z, z in enumerate(zs):\n",
        "        print('Generating image for latent code (%d/%d) ...' % (i_z, len(zs)))\n",
        "        if w_space:\n",
        "            image = Gs.components.synthesis.run(z, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "        else:\n",
        "            image = Gs.run(z, label, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        images.append(image[0])\n",
        "        PIL.Image.fromarray(image[0], 'RGB').save(f'{outdir}/z{i_z:04d}.png')\n",
        "\n",
        "    # If user wants to save a grid of the generated images\n",
        "    if grid:\n",
        "        print('Generating image grid...')\n",
        "        PIL.Image.fromarray(create_image_grid(np.array(images)), 'RGB').save(f'{outdir}/grid{prefix}.png')\n",
        "\n",
        "def interpolate(za, zb, n_steps):\n",
        "    zs = []\n",
        "    for i in range(n_steps):\n",
        "        a = i/(n_steps-1)\n",
        "        z = (1-a)*za + a*zb\n",
        "        zs.append(z)\n",
        "    return zs\n",
        "\n",
        "def lerp_video(Gs,                         # Path to pretrained model pkl file\n",
        "               za,\n",
        "               zb,\n",
        "               w_space=False,\n",
        "               truncation_psi=1.0,         # Truncation trick\n",
        "               slowdown=1,                 # Slowdown of the video (power of 2)\n",
        "               duration_sec=30.0,          # Duration of video in seconds\n",
        "               smoothing_sec=3.0,\n",
        "               mp4_fps=30,\n",
        "               mp4_codec=\"libx264\",\n",
        "               mp4_bitrate=\"16M\"):\n",
        "    # Sanity check regarding slowdown\n",
        "    message = 'slowdown must be a power of 2 (1, 2, 4, 8, ...) and greater than 0!'\n",
        "    assert slowdown & (slowdown - 1) == 0 and slowdown > 0, message\n",
        "    # Total duration of video and number of frames to generate\n",
        "    num_frames = int(np.rint(duration_sec * mp4_fps))\n",
        "    total_duration = duration_sec * slowdown\n",
        "\n",
        "    print(\"Generating latent vectors...\")\n",
        "    all_latents = interpolate(za, zb, n_steps=num_frames)\n",
        "    print(np.array(all_latents).shape)\n",
        "    make_grid = False\n",
        "    if np.array(all_latents).shape[1] > 1:\n",
        "        make_grid = True\n",
        "\n",
        "    #all_latents = scipy.ndimage.gaussian_filter(\n",
        "    #    all_latents,\n",
        "    #    [smoothing_sec * mp4_fps] + [0] * len(Gs.input_shape),\n",
        "    #    mode=\"wrap\"\n",
        "    #)\n",
        "\n",
        "    #all_latents /= np.sqrt(np.mean(np.square(all_latents)))\n",
        "    # Name of the final mp4 video\n",
        "    mp4 = f\"lerp-{slowdown}xslowdown.mp4\"\n",
        "\n",
        "    # Aux function to slowdown the video by 2x\n",
        "    def double_slowdown(latents, duration_sec, num_frames):\n",
        "        # Make an empty latent vector with double the amount of frames\n",
        "        z = np.empty(np.multiply(latents.shape, [2, 1, 1]), dtype=np.float32)\n",
        "        # Populate it\n",
        "        for i in range(len(latents)):\n",
        "            z[2*i] = latents[i]\n",
        "        # Interpolate in the odd frames\n",
        "        for i in range(1, len(z), 2):\n",
        "            # For the last frame, we loop to the first one\n",
        "            if i == len(z) - 1:\n",
        "                z[i] = (z[0] + z[i-1]) / 2\n",
        "            else:\n",
        "                z[i] = (z[i-1] + z[i+1]) / 2\n",
        "        # We also need to double the duration_sec and num_frames\n",
        "        duration_sec *= 2\n",
        "        num_frames *= 2\n",
        "        # Return the new latents, and the two previous quantities\n",
        "        return z, duration_sec, num_frames\n",
        "\n",
        "    while slowdown > 1:\n",
        "        all_latents, duration_sec, num_frames = double_slowdown(all_latents, duration_sec, num_frames)\n",
        "        slowdown //= 2\n",
        "\n",
        "    # Define the kwargs for the Generator:\n",
        "    Gs_kwargs = {\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
        "        'randomize_noise': False\n",
        "    }\n",
        "    label = np.zeros([1] + Gs.input_shapes[1][1:])\n",
        "\n",
        "    # Aux function: Frame generation func for moviepy.\n",
        "    def make_frame(t):\n",
        "        frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "        latents = all_latents[frame_idx]\n",
        "        # Get the images (with labels = None)\n",
        "        if w_space:\n",
        "            images = Gs.components.synthesis.run(latents, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "        else:\n",
        "            images = Gs.run(latents, label, **Gs_kwargs)\n",
        "        # Generate the grid for this timestamp:\n",
        "        if make_grid:\n",
        "            grid = create_image_grid(images)\n",
        "            ## grayscale => RGB\n",
        "            if grid.shape[2] == 1:\n",
        "                grid = grid.repeat(3, 2)\n",
        "            return grid\n",
        "        return images[0]\n",
        "\n",
        "    # Generate video using make_frame:\n",
        "    print(f'Generating interpolation video of length: {total_duration} seconds...')\n",
        "    videoclip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "    videoclip.write_videofile(os.path.join(outdir, mp4),\n",
        "                              fps=mp4_fps,\n",
        "                              codec=mp4_codec,\n",
        "                              bitrate=mp4_bitrate)\n",
        "\n",
        "def project_image_into_wspace(Gs, name, save_video=False):\n",
        "    # Load target image.\n",
        "    imgpath = name+'.jpg'\n",
        "    print(imgpath)\n",
        "    target_pil = PIL.Image.open(imgpath)\n",
        "    w, h = target_pil.size\n",
        "    s = min(w, h)\n",
        "    target_pil = target_pil.crop(((w - s) // 2, (h - s) // 2, (w + s) // 2, (h + s) // 2))\n",
        "    target_pil= target_pil.convert('RGB')\n",
        "    target_pil = target_pil.resize((Gs.output_shape[3], Gs.output_shape[2]), PIL.Image.ANTIALIAS)\n",
        "    target_uint8 = np.array(target_pil, dtype=np.uint8)\n",
        "    target_float = target_uint8.astype(np.float32).transpose([2, 0, 1]) * (2 / 255) - 1\n",
        "\n",
        "    # Initialize projector.\n",
        "    proj = Projector()\n",
        "    proj.set_network(Gs)\n",
        "    proj.start([target_float])\n",
        "\n",
        "    # Videooption\n",
        "    writer = None\n",
        "    if save_video:\n",
        "        writer = imageio.get_writer(f'{outdir}/{name}_proj.mp4', mode='I', fps=60, codec='libx264', bitrate='16M')\n",
        "\n",
        "    # Run projector.\n",
        "    with tqdm.trange(proj.num_steps) as t:\n",
        "        for step in t:\n",
        "            assert step == proj.cur_step\n",
        "            if writer is not None:\n",
        "                writer.append_data(np.concatenate([target_uint8, proj.images_uint8[0]], axis=1))\n",
        "            dist, loss = proj.step()\n",
        "            t.set_postfix(dist=f'{dist[0]:.4f}', loss=f'{loss:.2f}')\n",
        "\n",
        "    # Save results.\n",
        "    PIL.Image.fromarray(proj.images_uint8[0], 'RGB').save(f'{outdir}/{name}_proj.png')\n",
        "    np.savez(f'{outdir}/{name}_dlatents.npz', dlatents=proj.dlatents)\n",
        "    return proj.dlatents"
      ],
      "metadata": {
        "id": "G-Q2CsKrSdtX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zu Model spezifizieren\n",
        "modelpfad = \"WikiArt_Uncond2.pkl\"\n",
        "\n",
        "# Model laden\n",
        "tflib.init_tf()\n",
        "with dnnlib.util.open_url(modelpfad) as fp:\n",
        "    _G, _D, Gs = pickle.load(fp)"
      ],
      "metadata": {
        "id": "GdogN7FZS1m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Video-Interpolation zwischen 2 zufälligen Bildern\n",
        "za = np.random.normal(0,1,(1,512))\n",
        "zb = np.random.normal(0,1,(1,512))\n",
        "zs = interpolate(za, zb, 12)\n",
        "render_from_zs(Gs, zs, w_space=False, grid=True, class_idx=None)\n",
        "lerp_video(Gs,\n",
        "          za,\n",
        "          zb,\n",
        "          w_space=False,\n",
        "          truncation_psi=1.0,         # Truncation trick\n",
        "          slowdown=1,                 # Slowdown of the video (power of 2)\n",
        "          duration_sec=3.0,          # Duration of video in seconds\n",
        "          smoothing_sec=0.4,\n",
        "          mp4_fps=30,\n",
        "          mp4_codec=\"libx264\",\n",
        "          mp4_bitrate=\"16M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7xqIpxRSlpU",
        "outputId": "e6f1e7d5-d5dc-4c16-9bc7-987b6c806ac4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating image for latent code (0/12) ...\n",
            "Generating image for latent code (1/12) ...\n",
            "Generating image for latent code (2/12) ...\n",
            "Generating image for latent code (3/12) ...\n",
            "Generating image for latent code (4/12) ...\n",
            "Generating image for latent code (5/12) ...\n",
            "Generating image for latent code (6/12) ...\n",
            "Generating image for latent code (7/12) ...\n",
            "Generating image for latent code (8/12) ...\n",
            "Generating image for latent code (9/12) ...\n",
            "Generating image for latent code (10/12) ...\n",
            "Generating image for latent code (11/12) ...\n",
            "Generating image grid...\n",
            "Generating latent vectors...\n",
            "(90, 1, 512)\n",
            "Generating interpolation video of length: 3.0 seconds...\n",
            "[MoviePy] >>>> Building video out/lerp-1xslowdown.mp4\n",
            "[MoviePy] Writing video out/lerp-1xslowdown.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 90/91 [00:18<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: out/lerp-1xslowdown.mp4 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FRVWYdPqWCMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}