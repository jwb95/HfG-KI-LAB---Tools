{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqcXqpUy7iPp",
        "outputId": "ebfed962-46bc-4c00-d3aa-a4d2a1b1d780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modelscope==1.4.2\n",
        "!pip install open_clip_torch\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "FnBv-LhT8Sne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd modelscope"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF-ruxXk-SHg",
        "outputId": "7e7ee0dd-66f4-447a-e50d-b6ae5cf3c73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/modelscope\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.outputs import OutputKeys\n",
        "import pathlib\n",
        "\n",
        "model_dir = pathlib.Path('weights')\n",
        "snapshot_download('damo-vilab/modelscope-damo-text-to-video-synthesis',\n",
        "                   repo_type='model', local_dir=model_dir)"
      ],
      "metadata": {
        "id": "Z4BwQAAW_TsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline('text-to-video-synthesis', model_dir.as_posix())"
      ],
      "metadata": {
        "id": "Dk2P9K-tAKN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_dict = {'text' : 'a panda eating bamboo on a rock.'}\n",
        "output_video_path = pipe(prompt_dict,)[OutputKeys.OUTPUT_VIDEO]"
      ],
      "metadata": {
        "id": "YeTMQuB4BNTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ... /modelscope/output/"
      ],
      "metadata": {
        "id": "MVtGL9Sd3FIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import move\n",
        "\n",
        "def render_prompt_n_times(prompt, pipe, outdir, n=1):\n",
        "    for i in range(n):\n",
        "        print('Rendering video number '+str(i)+' ...')\n",
        "        output_video_path = pipe({'text':prompt},)[OutputKeys.OUTPUT_VIDEO]\n",
        "        move(output_video_path, outdir+str(i)+'.mp4')"
      ],
      "metadata": {
        "id": "-xaRuTh6FsUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing textfiles\n",
        "\n",
        "def get_sentences_from_file(filepath, repeats_per_prompt=1):\n",
        "    with open(filepath, 'r') as f:\n",
        "        txt = f.read()\n",
        "        # Clean Zeilenumbr√ºche\n",
        "        txt_ = \"\"\n",
        "        i = 0\n",
        "        while i < len(txt):\n",
        "            if txt[i] == '\\n' or txt[i] == \"\\'\":\n",
        "                i += 1\n",
        "            else:\n",
        "                txt_ += txt[i]\n",
        "                i += 1\n",
        "\n",
        "        # To prompts\n",
        "        prompts = []; prompt = \"\"; i=0\n",
        "        while i < len(txt_):\n",
        "            if txt_[i] == \" \" and len(prompt) == 0:\n",
        "                i += 1\n",
        "                continue\n",
        "            if txt_[i] == '.':\n",
        "                prompt += '.'\n",
        "                if i < len(txt_) - 1:\n",
        "                  if txt_[i + 1] in (\"'\", '\"'):\n",
        "                      i += 1\n",
        "                      prompt += txt_[i]\n",
        "                for j in range(repeats_per_prompt):\n",
        "                    prompts.append(prompt)\n",
        "                prompt = \"\"\n",
        "            else:\n",
        "                prompt += txt_[i]\n",
        "            i += 1\n",
        "        return prompts"
      ],
      "metadata": {
        "id": "MBF2uVFMHHmd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = get_sentences_from_file(\"txt.txt\")"
      ],
      "metadata": {
        "id": "6cSOwmzFHRvV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOP0lEvKMY88",
        "outputId": "51921a78-e46f-408b-d1c8-ba2af9aee30e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Once upon a time there was a sweet little girl.',\n",
              " 'Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next.',\n",
              " 'Once she gave her a little cap made of red velvet.',\n",
              " 'Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Riding Hood.',\n",
              " 'One day her mother said to her: \"Come Little Red Riding Hood.',\n",
              " 'Here is a piece of cake and a bottle of wine.',\n",
              " 'Take them to your grandmother.',\n",
              " 'She is sick and weak, and they will do her well.',\n",
              " 'Mind your manners and give her my greetings.',\n",
              " 'Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"',\n",
              " 'Little Red Riding Hood promised to obey her mother.',\n",
              " 'The grandmother lived out in the woods, a half hour from the village.',\n",
              " 'When Little Red Riding Hood entered the woods a wolf came up to her.',\n",
              " 'She did not know what a wicked animal he was, and was not afraid of him.',\n",
              " '\"Good day to you, Little Red Riding Hood.\"',\n",
              " '- \"Thank you, wolf.\"',\n",
              " '- \"Where are you going so early, Little Red Riding Hood?\" - \"To grandmothers.\"',\n",
              " '- \"And what are you carrying under your apron?\" - \"Grandmother is sick and weak, and I am taking her some cake and wine.',\n",
              " 'We baked yesterday, and they should give her strength.\"',\n",
              " '- \"Little Red Riding Hood, just where does your grandmother live?\" - \"Her house is a good quarter hour from here in the woods, under the three large oak trees.',\n",
              " 'Theres a hedge of hazel bushes there.',\n",
              " 'You must know the place,\" said Little Red Riding Hood.',\n",
              " 'The wolf thought to himself: \"Now there is a tasty bite for me.',\n",
              " 'Just how are you going to catch her?\" Then he said: \"Listen, Little Red Riding Hood, havent you seen the beautiful flowers that are blossoming in the woods? Why dont you go and take a look? And I dont believe you can hear how beautifully the birds are singing.',\n",
              " 'You are walking along as though you were on your way to school in the village.',\n",
              " 'It is very beautiful in the woods.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def render_each_prompt(list_of_prompts, pipe, outdir):\n",
        "    for i, prompt in enumerate(list_of_prompts):\n",
        "        print('Rendering video number '+str(i)+' ...')\n",
        "        output_video_path = pipe({'text':prompt},)[OutputKeys.OUTPUT_VIDEO]\n",
        "        move(output_video_path, outdir+str(i)+'.mp4')"
      ],
      "metadata": {
        "id": "pF2CJpRyNt3o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "render_each_prompt(\n",
        "    prompts,\n",
        "    pipe,\n",
        "    '/content/modelscope/output/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OepsSmn5RJgC",
        "outputId": "8b84b6be-e119-4a54-a0bc-8018f444023c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-04-17 12:51:13,372 - modelscope - WARNING - task text-to-video-synthesis input definition is missing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering video number 0 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-04-17 12:52:15,868 - modelscope - WARNING - task text-to-video-synthesis output keys are missing\n",
            "2023-04-17 12:52:15,871 - modelscope - WARNING - task text-to-video-synthesis input definition is missing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering video number 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-04-17 12:53:17,095 - modelscope - WARNING - task text-to-video-synthesis output keys are missing\n",
            "2023-04-17 12:53:17,098 - modelscope - WARNING - task text-to-video-synthesis input definition is missing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering video number 2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-04-17 12:54:18,732 - modelscope - WARNING - task text-to-video-synthesis output keys are missing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "gnvRcbWh4CGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *\n",
        "\n",
        "def concatenate(video_clip_paths, output_path, method=\"compose\"):\n",
        "    \"\"\"Concatenates several video files into one video file\n",
        "    and save it to `output_path`. Note that extension (mp4, etc.) must be added to `output_path`\n",
        "    `method` can be either 'compose' or 'reduce':\n",
        "        `reduce`: Reduce the quality of the video to the lowest quality on the list of `video_clip_paths`.\n",
        "        `compose`: type help(concatenate_videoclips) for the info\"\"\"\n",
        "    # create VideoFileClip object for each video file\n",
        "    clips = [VideoFileClip(c) for c in video_clip_paths]\n",
        "    if method == \"reduce\":\n",
        "        # calculate minimum width & height across all clips\n",
        "        min_height = min([c.h for c in clips])\n",
        "        min_width = min([c.w for c in clips])\n",
        "        # resize the videos to the minimum\n",
        "        clips = [c.resize(newsize=(min_width, min_height)) for c in clips]\n",
        "        # concatenate the final video\n",
        "        final_clip = concatenate_videoclips(clips)\n",
        "    elif method == \"compose\":\n",
        "        # concatenate the final video with the compose method provided by moviepy\n",
        "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
        "    # write the output video file\n",
        "    final_clip.write_videofile(output_path)"
      ],
      "metadata": {
        "id": "7ybmFk_DRPX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clips_dir = \"/content/modelscope/output/\"\n",
        "concatenate([clips_dir+i for i in os.listdir(clips_dir) if i.endswith('mp4')], 'concatenated.mp4')"
      ],
      "metadata": {
        "id": "MSNElEni4GO1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}